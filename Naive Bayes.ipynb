{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Train.csv')\n",
    "x_train = df.drop(columns=['class'])\n",
    "y_train= df['class']\n",
    "#y_trainsample = y_train.head(100)\n",
    "y_trainsample = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in x_train.columns:\n",
    "    if x_train[column].dtype==type(object):\n",
    "         labelencoder = LabelEncoder()\n",
    "         x_train[column] = labelencoder.fit_transform(x_train[column])\n",
    "#x_trains = x_train.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "y_train = labelencoder.fit_transform(y_trainsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = GaussianNB()\n",
    "model2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('Test.csv')\n",
    "x_test = df2.drop(columns = ['class'])\n",
    "y_test= df2['class']\n",
    "#y2 = y1.head(100)\n",
    "\n",
    "for column in x_test.columns:\n",
    "    if x_test[column].dtype == type(object):\n",
    "        labelencoder1 = LabelEncoder()\n",
    "        x_test[column] = labelencoder1.fit_transform(x_test[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "y_test = labelencoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class labels on training data\n",
    "pred_labels_tr = model2.predict(x_train)\n",
    "    # Predict class labels on a test data\n",
    "pred_labels_te = model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluation on Training Data -----\n",
      "Accuracy Score:  0.5342732172767181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.02      0.03     58630\n",
      "           1       0.53      0.98      0.69     67343\n",
      "\n",
      "    accuracy                           0.53    125973\n",
      "   macro avg       0.51      0.50      0.36    125973\n",
      "weighted avg       0.51      0.53      0.39    125973\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('----- Evaluation on Training Data -----')\n",
    "score_tr = model2.score(x_train, y_train)\n",
    "print('Accuracy Score: ', score_tr)\n",
    "# Look at classification report to evaluate the model\n",
    "print(classification_report(y_train, pred_labels_tr))\n",
    "print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.45031937544357703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.04      0.07     12833\n",
      "           1       0.44      1.00      0.61      9711\n",
      "\n",
      "    accuracy                           0.45     22544\n",
      "   macro avg       0.69      0.52      0.34     22544\n",
      "weighted avg       0.72      0.45      0.30     22544\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Use score method to get accuracy of the model\n",
    "print('----- Evaluation on Test Data -----')\n",
    "score_te = model2.score(x_test, y_test)\n",
    "print('Accuracy Score: ', score_te)\n",
    "# Look at classification report to evaluate the model\n",
    "print(classification_report(y_test, pred_labels_te))\n",
    "print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
